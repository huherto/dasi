---
title: "Unit4: Inference for numerical variables"
output: html_document
---

Introduction
-----------------------------
- Comparing two means.
- Bootstrapping.
- Working with small samples.
- Comparing many means.

### Unit 4, Part 1: Hypothesis Testing for Paired Data

Analyzing paired data:

- When two sets of observations have this special
  correspondence (not independent), they are said to be
  paired.
  
- To analyze paired data, it is often useful to look at the difference
  in outcomes of each pair of observations:
  
  ````
  diff = read score - wirte score
  ````
  
- It is importante that we always substract using a consistent order.

Parameter of interest: ${\mu_{diff}}$

Point estimate: ${\bar{x}_{diff}}$
  
#### Hypotheses for paired means

1. Set the hypotheses:

${H_0: \mu_{diff} = 0}$

${H_A: \mu_{diff} \neq 0}$

2. Calculate point estimate. ${\bar{x}_{diff}}$

3. Check conditions.

    1. Independence: Sample observations must be independent.
    
    2. Sample size/skew: n >= 30, larger if the population is very skewed.
  
4. Draw sampling distribution, shade p-value, calculate test statistic.

    ${Z = \dfrac{x_{diff} - \mu_{diff}}{SE_{\bar{x}_{diff}} } }$

5. Make a decision, and interpret it in context of the research question.

````{r}
mu = 0
mean=-0.545
s = 8.887
n = 200
se = s/(sqrt(n))
z = (mean - mu)/se
pvalue=pnorm(z) * 2
c(se, z, pvalue)
````

### Unit 4, Part 1: Confidence Intervals for Paired Data

Estimated the difference between paired means.

  point estimate ${\pm}$ margin of error
  
  ${ SE_{\bar{x}_{diff}} = \dfrac{s_{diff}}{ \sqrt{n_{diff}} } }$ and
  ${ \bar{x}_{diff}  \pm z * SE_{\bar{x}_{diff}} }$

  ${ \bar{x}_{diff}  \pm z * \dfrac{s_{diff}}{ \sqrt{n_{diff}} } }$


Compare pvalue with ${ \alpha }$
````{r}
z=qnorm((1 - .95)/2)
ci1 = mean - z*se
ci2 = mean + z*se
c(se, z, ci1, ci2) 

````

### Unit 4, Part 1: Comparing Independent Means.
- Confidence intervals.
- Hypothesis tests

#### Estimating the difference between independent means.

Parameter of interest: ${ \mu_1 - \mu_2}$

Point estimate: ${ \bar{x}_1 - \bar{x}_2  }$

Point estimate ${ \pm }$ Margin of Error: ${  (\bar{x}_1 - \bar{x}_2) \pm z* SE_{\bar{x}_1 - \bar{x}_2} }$

Standard error of difference between two independent means:
${  SE_{(\bar{x}_1 - \bar{x}_2)} = \sqrt{ \frac{s_1^2}{n_1} + \frac{s_2^2}{n_2} } }$

#### Conditions of independence for comparing two independent means.

1. Independence:

  - Within groups. random and n <= 10% population.
  
  - Between groups. (non-paired)
  
2. Sample size/skew: n1 >= 30 and n2 >= 30.

Example:

````{r}
x1 = 41.8
x2 = 39.4
s1 = 15.14
s2=15.12
n1=505
n2=667
z=1.96
se = sqrt(s1^2/n1 + s2^2/n2)
me = z*se
mean = x1 - x2
sprintf("se=%.4f, me=%.4f, mean=%.4f, ci(%.4f, %.4f)", se, me, mean, mean - me, mean + me)
````

#### Testing for a difference between independence means.

${ H_0: \mu_1 - \mu_2 = 0}$

${ H_A: \mu_1 - \mu_2 \ne 0}$

Point estimate:${ {(\bar{x}_1 - \bar{x}_2)} \tilde{} N(mean=0, SE = 0.89) }$

````{r}
x=seq(-3,3,length=200)
y=dnorm(x,mean=0,sd=0.89)
plot(x,y,type="l",lwd=1,col="blue")

z=(mean - 0)/se
pvalue=(1 - pnorm(z))*2
sprintf("z=%.4f, pvalue=%.4f", z, pvalue)
if (pvalue < .05) {
  print("Reject null hypothesis")
}
````

### Unit 4, Part 2: Bootstraping

1. Tale a bootstrap sample - random sample taken *with replacement* from the original sample, of the same size as the original sample.

2. Calculate the bootstrap statistic - a statistic such as mean, median, proportion, etc. computed on the bootstrap samples.

3. Repeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics.

### Unit 4, Part 3: t Distribution

A large sample ensures that...

1. The sample distribution of the mean is nearly normal.

2. The estimate of the standar error is reliable. ${ SE = \dfrac{s}{ \sqrt{n}} }$

* When n is small and ${\sigma}$ is unkown(almost always), use the **t distribution** to address the uncertanty of the standard error estimate.

* t distribution is bell shaped, but thicker than the normal.

    + Observations more likely to fall beyond 2 SDs from the mean.
  
    + Extra thick tails helpful for mitigating the effect of a less reliable estimate for the standard error of the sampling distribution.
  
    + Always center at 0 (like the standard normal)
    
    + Has one parameter: **degrees of freedom (df) ** - determines thickness of tails
    
    + Approaches normality as degrees of freedom increases.
    
#### Use the t statistic.

* for inference on a mean when
    + ${ \sigma }$ is unknown.
    + n < 30
* Calculated the same way.
    + ${ T = \dfrac{obs - null}{SE} }$
* p-value (same definition)
    + one or two tail area, based on ${H_A}$
    + using R, applet, or table.
    
### Unit 4, Part 3: Inference for a Small Sample Mean.

#### Estimating the mean (based on a small sample)

point estimate ${ \pm }$ margin of error

${ \bar{x} \pm t_{df}^*SE_\bar{x}}$

${ \bar{x} \pm t_{df}^*\dfrac{s}{\sqrt{n}}}$

Degrees of freedom for t statistics for inference on one sample mean: ${df = n - 1}$

    
${ \bar{x} \pm t_{n - 1}^*\dfrac{s}{\sqrt{n}}}$

````{r}
mean = 52.1;
s = 45.1;
n = 22;
t = abs(qt(0.025, df=n-1));
se = s/sqrt(n)
ci1 = mean - t*se;
ci2 = mean + t*se
sprintf("t=%.4f, se=%.4f, (%.4f, %.4f)", t, se, ci1, ci2);
````

#### Hypothesis testing.

Asume:

  ${H_0: \mu = 30 }$ and ${H_A: \mu \ne 30 }$
  

````{r}
mu = 30;
t = (mean - mu)/se;
pvalue = (1 - pt(t, df = n - 1)) * 2; # Two tails.

sprintf("t=%.4f, pvalue=%.4f, rejectH0=%s", t, pvalue, (pvalue < 0.05));

````

### Unit 4, Part 3: Inference for Comparing Two Small Sample Means.

${ SE = \sqrt{ \dfrac{s_1^2}{n_1} + \dfrac{s_2^2}{n_2} } }$

${ df = min(n_1 - 1, n_2 - 1) }$

#### Confidence intervals

point estimate ${\pm}$ margin of error

${(\bar{x_1} - \bar{x_2} ) \pm t_{df}^* SE_{ (\bar{x_1} - \bar{x_2}) } }$


#### Hypthesis testing

Asume:

${ H_0: \mu_{1} - \mu_{2} = 0  }$

${ H_A: \mu_{1} - \mu_{2} \ne 0  }$

${ T_{df} = \dfrac{obs - null}{ SE } }$

${ T_{df} = \dfrac{(\bar{x_1} - \bar{x_2} ) - (\mu_1 - \mu_2) }{SE_{ (\bar{x_1} - \bar{x_2}) }} }$





````{r}
x1 = 52.1;
s1 = 45.1;
n1 = 22;

x2 = 27.1;
s2 = 26.4;
n2 = 22;

df = min(n1 - 1, n2 - 1);
se = sqrt( s1^2/n1 + s2^2/n2 );
mean = x1 - x2;
t = abs(qt(0.025, df=df))
me = t * se;
ci1 = mean - me;
ci2 = mean + me;
sprintf("mean=%.4f, t=%.4f, se=%.4f, (%.4f, %.4f)", mean, t, se, ci1, ci2);

mu = 0;
t = (mean - mu)/se;
pvalue = (1 - pt(t, df = df)) * 2; # Two tails.

sprintf("t=%.4f, pvalue=%.4f, rejectH0=%s", t, pvalue, (pvalue < 0.05));

````

### Unit 4, Part 4: 1 Comparing More Than Two Means

### Unit 4, Part 4: 2 ANOVA

${H_0}$ : The mean outcome is the same across all categories.

${\mu_1 = \mu_2 = \mu_3 = \mu_4 }$

${H_A}$ At lest one pair of means are different from each other.

##### Variablity partitioning.

Example: Total variability in vocabulary scores is divided in variability attributed to social class and variability attributed to other factores.

##### Sum of Squares Total (SST)

- Measures the **total variability** in the response variable.
 
- Calculated very similary to variance(except not scaled by the sample size)

${ SST = \sum\limits_{i=1}^{n} ( y_i - \bar{y})^2 }$

${y_i}$ : value of the response variable for each observation.

${\bar{y}}$ : grand mean of the response variable.

##### Sum of Squares Groups (SSG)

- Measures the variability **between groups**.

- **Explained variability:** deviation of group mean from overall mean, weighted by sample size.

${ SSG = \sum\limits_{j=1}^{k} n_j( \bar{y_j} - \bar{y})^2 }$

${ n_j }$ : Number of observation in group j.

${\bar{y_j}}$: Mean of the response variable for group j.

${ \bar{y} }$ : Grand mean of the response variable.

##### Sum of Squares Error (SSE)

- Measures the variability **within groups**.

- **Unexplained variability:** unexplained by the group variable, due to other reasons.

${ SSE = SST - SSG }$

##### Degrees of freedom

- Total: ${ df_T = n - 1}$

- Group: ${ df_G = k - 1}$

- Error: ${ df_E = df_T - df_G }$

##### P-Value

- **p-value** is the probability of at least as large a ratio between the "between" and "within" group variabilities if in fact the means of all groups are equal.

- Area under the F curve, with degrees of freedom ${df_G}$ and ${df_E}$, above the observed F statistic.


````{r}
n = 795;
k = 4;

DFG= k - 1;
DFT= n - 1;
DFE=DFT - DFG;

SSG=236.56;
SST=3106.36;
SSE=SST-SSG;

MSG=SSG/DFG;
MSE=SSE/DFE;

Fvalue = MSG/MSE;
pvalue = pf(Fvalue, DFG, DFE, lower.tail = FALSE);

sprintf("Group: DFG=%.4f, SSG=%.4f, MSG=%.4f, Fvalue=%.4f,pvalue=%.4f", DFG, SSG, MSG, Fvalue,pvalue);
sprintf("Error: DFG=%.4f, SSE=%.4f, MSE=%.4f",DFE, SSE, MSE);
sprintf("Total: DFT=%.4f, SST=%.4f",DFT, SST);

````

##### Conclusion

If p-value is small (less than ${\alpha}$), reject ${H_0}$

  * The data provide convincing evidence that at least on pair of population means are different from each other. (But we can't tell which one)
  
If p-value is large, fail to reject ${H_0}$.

  * The data do not provide convincing evidence that one pair of population means are different from each other, the observed differences in sample means are attributable to sampling variability (or chance).
  

### Unit 4, Part4: 3 Conditions for ANOVA

1. Independence.

  - Within groups.
  
  - Between groups.
  
2. Approximate normality within each group.

3. Equal variance.

### Unit 4, Part 4: 4 Multiple Comparisons

##### Bonferroni correction

${\alpha \star = \alpha / K }$

${ K : \text{number of comparisons}, K = \dfrac{k(k-1)}{2} }$

##### Standard error for multiple pairwise comparisons.

${ SE = \sqrt{\dfrac{MSE}{n_1} + \dfrac{MSE}{n_2} } }$

##### Degrees of freedom for multipe pairwise comparisons.

${df = df_E }$

````{r}
mean1=5.07;
n1= 41;
mean2=6.76;
n2=331;
k = 4
mu = 0;

K=k*(k-1)/2;
alpha=.05/K;

SE = sqrt(MSE/n1 + MSE/n2);
tscore=abs(((mean1 - mean2) - mu)/SE);
pvalue=2 * pt(tscore, df=DFE, lower.tail = FALSE);
sprintf("SE=%.4f, tscore=%.4f, alpha=%.8f, pvalue=%.8f, rejectH0=%s",SE, tscore, alpha, pvalue,(pvalue < alpha));

````
  

